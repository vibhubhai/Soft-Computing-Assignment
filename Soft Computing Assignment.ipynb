{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1) Explain Soft Computing.\n",
    "\n",
    "Sol) Soft computing is a set of computational techniques that aim to solve complex problems by mimicking human reasoning. It includes approaches like fuzzy logic, genetic algorithms, neural networks, and probabilistic reasoning. Unlike traditional hard computing, which relies on exact mathematical models, soft computing deals with approximation, tolerance for imprecision, and uncertainty. It is used in real-world applications such as pattern recognition, decision-making, and optimization, where exact solutions are difficult to obtain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2) Explain different types of distances and cost functions used in ML.\n",
    "\n",
    "Sol) In machine learning, distances and cost functions are used to measure similarity, dissimilarity, or error in a model's predictions. Here are some commonly used types:\n",
    "\n",
    "Euclidean Distance: Measures the straight-line distance between two points in a multi-dimensional space. It is used in algorithms like k-NN and clustering.\n",
    "‚Äã\n",
    " \n",
    "Manhattan Distance: Also known as the L1 norm, it calculates the sum of absolute differences between the coordinates of two points.\n",
    "\n",
    "\n",
    "Cosine Similarity: Measures the cosine of the angle between two vectors, used to determine how similar two vectors are, often in text or document analysis.\n",
    "\n",
    "Cosine¬†Similarity: Measures the cosine of the angle between two vectors, used to determine how similar two vectors are, often in text or document analysis.\n",
    "\n",
    " \n",
    "Cost Functions: In supervised learning, cost functions quantify the error of a model's predictions.\n",
    "\n",
    "1. Mean Squared Error (MSE): Measures the average squared difference between predicted and actual values, commonly used in regression.\n",
    "\n",
    " \n",
    "2. Cross-Entropy Loss: Used for classification tasks, it measures the difference between predicted probabilities and the true labels.\n",
    "\n",
    "These distances and cost functions help machine learning algorithms optimize their predictions and make decisions based on the available data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3) explain use of activation function in neural network with example.\n",
    "\n",
    "Sol)Activation functions in neural networks introduce non-linearity, allowing the network to model complex relationships in the data. Without activation functions, a neural network would only be able to model linear relationships, regardless of the number of layers.\n",
    "\n",
    "Uses of Activation Functions:\n",
    "1. Non-Linearity: They help the neural network learn complex patterns and make decisions that aren't just linear.\n",
    "2. Control Output Range: Activation functions control the range of output values, making them more suitable for specific tasks (e.g., probabilities in classification).\n",
    "3. Gradient Propagation: Activation functions help with backpropagation by enabling gradients to flow through the network during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4) Explain fuzzy sets and crisp sets also explain different types of membership functions.\n",
    "\n",
    "Sol) \n",
    "1. Crisp Sets: In a crisp set, elements either fully belong or do not belong to the set. The membership function takes binary values, 0 or 1. For example, in a set of \"tall people,\" a person is either classified as tall (1) or not (0).\n",
    "\n",
    "2. Fuzzy Sets: In a fuzzy set, elements can partially belong to the set with a degree of membership ranging from 0 to 1. This allows for more flexibility and represents real-world uncertainty or vagueness. For instance, in a fuzzy set of \"tall people,\" someone who is somewhat tall may have a membership value of 0.6.\n",
    "\n",
    "# Types of Membership Functions:\n",
    "Membership functions define the degree of membership of an element in a fuzzy set. Common types include:\n",
    "\n",
    "1. Triangular Membership Function: This function is shaped like a triangle and defines a simple way to assign membership values. It has a peak at the center and tapers off linearly on either side.\n",
    "\n",
    "Example: For \"medium height,\" the triangle might peak at 170 cm, with decreasing membership values as height moves away from 170 cm.\n",
    "\n",
    "2. Trapezoidal Membership Function: This function is similar to the triangular function but with a flat top, allowing for a more gradual transition. It is useful when a range of values is considered to have full membership.\n",
    "\n",
    "Example: For \"medium height,\" a person between 160 cm and 180 cm could have full membership (value 1), and the membership gradually decreases outside this range.\n",
    "\n",
    "3. Gaussian Membership Function: This function is bell-shaped and defined by the Gaussian (normal) distribution. It allows for smooth transitions between membership values and is useful in cases where the transition between sets is not linear.\n",
    "\n",
    "Example: For \"medium temperature,\" the membership value might peak at 25¬∞C and slowly decrease as the temperature moves away from 25¬∞C.\n",
    "\n",
    "\n",
    "These membership functions enable fuzzy logic systems to handle imprecision and uncertainty in real-world data and decision-making processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5) Explain the chain rule and elitism.\n",
    "\n",
    "Sol) \n",
    "# Chain Rule:\n",
    "The chain rule is a fundamental concept in calculus used to compute the derivative of a composite function. It helps in finding the rate of change of a function that is composed of other functions.\n",
    "\n",
    "\n",
    "Example:\n",
    "For y=sin(3x), apply the chain rule:\n",
    "\n",
    "Outer function: \n",
    "sin(u), where u=3x, derivative of sin(u) is cos(u).\n",
    "Inner function: u=3x, derivative of 3x is 3.\n",
    "So, by the chain rule:\n",
    "\n",
    "dy/dx = cos(3x)√ó3=3cos(3x)\n",
    "# Elitism:\n",
    "Elitism is a concept used in evolutionary algorithms, such as genetic algorithms. It refers to the practice of carrying over the best individuals (solutions) from one generation to the next, without modification. This ensures that the best solutions are not lost during the selection and reproduction process.\n",
    "\n",
    "Why Elitism is Important:\n",
    "1. Preservation of Quality: By retaining the best solutions, elitism prevents the deterioration of solution quality over generations.\n",
    "2. Faster Convergence: Elitism can help the algorithm converge more quickly towards an optimal solution by maintaining high-quality solutions in the population.\n",
    "In genetic algorithms, elitism ensures that the best individuals (e.g., highest fitness scores) are directly passed to the next generation, promoting better performance and stability in the search for optimal solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6) Design an and gate using perceptron , start with random weights and use the weight update algorithm to adjust weights\n",
    "\n",
    "Sol) For an AND gate, the input-output pairs are:\n",
    "\n",
    "(0, 0) ‚Üí 0\n",
    "(0, 1) ‚Üí 0\n",
    "(1, 0) ‚Üí 0\n",
    "(1, 1) ‚Üí 1\n",
    "\n",
    "y=activation(w1 ‚ãÖ x1 + w2 ‚ãÖ x2 + b)\n",
    "Where:\n",
    "\n",
    ". ùë§1 and w2 are weights.\n",
    ". ùëè is the bias.\n",
    ". ùë•1, ùë•2 are the inputs.\n",
    ". activation(z)={ 1, if¬†z‚â•0\n",
    "              {0, if¬†z<0\n",
    "\n",
    "Initialize the weights and bias randomly:\n",
    "\n",
    "ùë§1=0.5, ùë§2=‚àí0.5, and ùëè=0.1 (These values can be randomized).\n",
    "\n",
    "The weight update rule for a perceptron is:\n",
    "\n",
    "ùë§1=ùë§1+Œîùë§1\n",
    " \n",
    "ùë§2=ùë§2+Œîùë§2\n",
    " \n",
    "ùëè=ùëè+Œîùëè\n",
    "\n",
    "\n",
    "The training process involves updating the weights based on the errors between predicted and target outputs. The algorithm proceeds through the following steps:\n",
    "\n",
    "1. Initialize weights and bias.\n",
    "2. For each training sample (input-output pair):\n",
    "    . Calculate the weighted sum: ùëß=ùë§1‚ãÖùë•1+ùë§2‚ãÖùë•2+ùëè.\n",
    "    . Apply the activation function to get the output ùë¶predicted\n",
    "    . Compute the error:error=ùë¶target ‚àí ùë¶predicted.\n",
    "\n",
    "Update the weights and bias using the weight update rule.\n",
    "3. Repeat for several epochs (iterations over the full training set) until convergence.\n",
    "\n",
    "1st Training Sample: (0, 0) ‚Üí 0\n",
    "Weighted sum: ùëß=0.5 ‚ãÖ 0 + (‚àí0.5) ‚ãÖ 0 + 0.1 = 0.1\n",
    "Predicted output:ùë¶predicted = 1 (since ùëß‚â•0)\n",
    "Error: error= 0 ‚àí 1 = ‚àí1\n",
    "\n",
    "2nd Training Sample: (0, 1) ‚Üí 0\n",
    "Weighted sum: ùëß=0.5 ‚ãÖ 0 + (‚àí0.5) ‚ãÖ 1 + 0 = ‚àí0.5\n",
    "Predicted output: ùë¶predicted = 0 (since ùëß<0)\n",
    "Error: error = 0 ‚àí 0 = 0 \n",
    "No update needed as the prediction is correct.\n",
    "\n",
    "3rd Training Sample: (1, 0) ‚Üí 0\n",
    "Weighted sum: z = 0.5 ‚ãÖ 1 + (‚àí0.5) ‚ãÖ 0 + 0 = 0.5\n",
    "Predicted output: ypredicted = 1 (since ùëß‚â•0)\n",
    "Error: error=0‚àí1=‚àí1\n",
    "Update weights and bias:\n",
    ". Œîùë§1= 0.1 ‚ãÖ (‚àí1) ‚ãÖ 1=‚àí0.1\n",
    ". Œîw2 = 0.1 ‚ãÖ (‚àí1) ‚ãÖ 0 = 0\n",
    ". Œîb = 0.1 ‚ãÖ (‚àí1) = ‚àí0.1\n",
    "New weights: \n",
    "ùë§1 = 0.5 ‚àí 0.1 = 0.4, \n",
    "ùë§2 = ‚àí0.5, \n",
    "b = 0 ‚àí 0.1 = ‚àí0.1\n",
    "\n",
    "4th Training Sample: (1, 1) ‚Üí 1\n",
    ". Weighted sum: z=0.4‚ãÖ1+(‚àí0.5)‚ãÖ1+(‚àí0.1)=‚àí0.2\n",
    ". Predicted output: ùë¶predicted = 0 (since ùëß<0)\n",
    ". Error: error = 1 ‚àí 0 = 1\n",
    ". Update weights and bias:\n",
    "    . Œîùë§1 = 0.1 ‚ãÖ 1‚ãÖ1 = 0.1\n",
    "    . Œîw2 = 0.1 ‚ãÖ 1‚ãÖ1 = 0.1\n",
    "    . Œîb = 0.1 ‚ãÖ 1 = 0.1\n",
    "    . New weights: ùë§1 = 0.4 + 0.1 = 0.5, ùë§2 = ‚àí0.5 + 0.1 = ‚àí0.4, b = ‚àí0.1 + 0.1 = 0\n",
    "\n",
    "Repeat the above process for several epochs until the perceptron correctly predicts all inputs. After sufficient training, the weights should converge to values that allow the perceptron to mimic the AND gate behavior. The final values for weights and bias will typically be:\n",
    "\n",
    ". ùë§1‚Äã = 1,ùë§2 = 1, ùëè=‚àí0.5\n",
    "This will give the correct AND gate output for all inputs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6) Compare and contrast between biological neurons and artificial neurons. Show the basic mathematical mode of perceptron.\n",
    "\n",
    "Sol) \n",
    "# Biological Neurons\n",
    "1. Composed of dendrites, cell body (soma), axon, and synapses.\n",
    "2. Receive electrical signals through dendrites.\n",
    "3. Process signals through the soma and determine if an action potential is triggered.\n",
    "4. Send signals through the axon to other neurons or muscles.\n",
    "5. Connected to thousands of other neurons via synapses.\n",
    "6. Adjusts synaptic strengths through mechanisms like Hebbian learning or backpropagation.\n",
    "7. Triggered by reaching a threshold potential, resulting in an all-or-nothing spike.\n",
    "8. Operates at the millisecond scale\n",
    "9. \tHighly adaptable and self-repairing\n",
    "10. Part of a vast network with billions of neurons in the brain.\n",
    "\n",
    "# Artifical Neurons\n",
    "1. Represented as a computational unit with inputs, weights, a bias, and an activation function.\n",
    "2. Accept numerical inputs from datasets or other artificial neurons.\n",
    "3. Compute a weighted sum of inputs and apply an activation function to determine the output.\n",
    "4. Produce a single numerical output to pass to the next layer of the network.\n",
    "5. Connected to other neurons in a network through weighted links.\n",
    "6. Adjusts weights using algorithms like gradient descent during training.\n",
    "7. Uses mathematical activation functions (e.g., sigmoid, ReLU) to produce outputs.\n",
    "8. Operates at a much faster computational speed.\n",
    "9. Requires explicit programming and does not self-repair.\n",
    "10. Operates as part of a relatively simpler artificial neural network.\n",
    "\n",
    "# Mathematical Model of a Perceptron\n",
    "A perceptron is the simplest type of artificial neuron and the foundation of artificial neural networks. It performs binary classification by applying a linear decision boundary. The perceptron computes a weighted sum of its inputs and passes it through an activation function to determine the output.\n",
    "\n",
    "Compute the weighted sum:\n",
    "\n",
    "ùëß = ‚àë ùë§ùëñ . ùë•ùëñ + ùëè = ùëä^ùëá . ùëã + ùëè\n",
    "\n",
    "Apply the activation function to get the output:\n",
    "\n",
    "ùë¶=ùëì(ùëß)={1, if ùëß‚â•0\n",
    "        0, ifùëß<0\n",
    "\n",
    "# Diagram of a Perceptron:\n",
    "A perceptron can be visually represented as:\n",
    "\n",
    "    x_1 ---- w_1 ----|\n",
    "    x_2 ---- w_2 ----|--> ( Œ£ weighted sum + bias ) --> Activation Function --> Output (y)\n",
    "    ...              |\n",
    "    x_n ---- w_n ----|\n",
    "                     b (bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7) derive an expression for gradient descent with backpropagation\n",
    "\n",
    "Sol) \n",
    "# Gradient Descent with Backpropagation:\n",
    "Gradient descent is an optimization technique used to minimize the error (or loss) in a neural network by updating the weights. Backpropagation is the method used to compute the gradients of the loss function with respect to the weights, which is then used in gradient descent to update the weights.\n",
    "\n",
    "Let's derive the expressions for gradient descent and backpropagation step-by-step.\n",
    "\n",
    "1. Objective of Gradient Descent:\n",
    "We want to minimize the loss function \n",
    "ùêø\n",
    "L by adjusting the weights of the neural network. The weights are updated iteratively to reduce the loss.\n",
    "The gradient descent update rule is:\n",
    "\n",
    "ùë§^(ùë°+1) = ùë§^(ùë°) ‚àí ùúÇ ‚ãÖ ‚àÇùêø / ‚àÇùë§\n",
    "\n",
    "2. Backpropagation Overview:\n",
    "Backpropagation is used to compute the gradients of the loss function with respect to the weights. It uses the chain rule of calculus to propagate the error from the output layer back to the input layer, updating the weights.\n",
    "\n",
    "Given a neural network with layers indexed as ùëô=1,2,...,ùêø, where ùêø is the number of layers, and each layer has activations ùëé^(ùëô) and weights ùë§^(ùëô), the general procedure is:\n",
    "\n",
    ". Compute the output of the network for a given input \n",
    "ùë•, using forward propagation.\n",
    ". Compute the error at the output layer.\n",
    ". Use backpropagation to compute the gradients of the loss function with respect to the weights.\n",
    "\n",
    "3. Forward Pass (Feedforward):\n",
    "For each layer ùëô, the output is calculated as:\n",
    "\n",
    "ùëß^(ùëô) = ùë§^(ùëô) ‚ãÖ ùëé^(ùëô‚àí1) + ùëè^(ùëô)\n",
    "\n",
    "ùëé^(ùëô) = ùúé(ùëß^(ùëô))\n",
    "\n",
    "4. Gradient Descent Update:\n",
    "Once we have the gradients, we update the weights and biases using the gradient descent update rule:\n",
    "\n",
    "Update the weights:\n",
    "ùë§^(ùëô) = ùë§^(ùëô) ‚àí ùúÇ ‚ãÖ ‚àÇùêø / ‚àÇùë§^(ùëô)\n",
    "\n",
    "Update the biases:\n",
    "ùëè^(ùëô) = ùëè^(ùëô) ‚àí ùúÇ ‚ãÖ ‚àÇùêø / ‚àÇùëè^(ùëô)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8) obtain the truth table for given expressions and determine whether they are tautology or contradiction.\n",
    "i) (P v Q) => (~P)\n",
    "ii)(P => Q) = (~P v Q)\n",
    "iii) ((P => Q) ^ (Q => P) = (P = Q)\n",
    "\n",
    "Sol) \n",
    "P\tùëÑ   ¬¨ùëÉ  P‚à®ùëÑ (ùëÉ‚à®ùëÑ)‚áí(¬¨ùëÉ)\n",
    "T\tT\tF\t T\t    F\n",
    "T\tF\tF\t T\t    F\n",
    "F\tT\tT\t T\t    T\n",
    "F\tF\tT\t F\t    T\n",
    "Interpretation:\n",
    ". The result of (ùëÉ‚à®ùëÑ)‚áí(¬¨ùëÉ) is false in some cases.\n",
    ". Therefore, the expression is not a tautology (since it is false in some cases).\n",
    ". The expression is not a contradiction (since it is true in some cases).\n",
    "Thus, this expression is a contingency.\n",
    "\n",
    "P\tùëÑ\t¬¨ùëÉ  P‚áíùëÑ     ¬¨P‚à®Q    (ùëÉ‚áíùëÑ)=(¬¨ùëÉ‚à®ùëÑ)\n",
    "T\tT\tF\tT\t    T       \tT\n",
    "T\tF\tF\tF\t    F\t        T\n",
    "F\tT\tT\tT\t    T\t        T\n",
    "F\tF\tT\tT\t    T\t        T\n",
    "Interpretation:\n",
    "The expression (ùëÉ‚áíùëÑ)=(¬¨ùëÉ‚à®ùëÑ) is true in all cases.\n",
    "Therefore, the expression is a tautology (since it is true for all combinations of truth values).\n",
    "\n",
    "\n",
    "P\tùëÑ   ùëÉ‚áíùëÑ     ùëÑ‚áíùëÉ     (ùëÉ‚áíùëÑ)‚àß(ùëÑ‚áíùëÉ)     P=Q     ((P‚áíQ)‚àß(Q‚áíP))=(P=Q)\n",
    "T\tT\t T\t      T\t            T\t        T\t        T\n",
    "T\tF\t F\t      T\t            F\t        F\t        T\n",
    "F\tT\t T\t      F\t            F\t        F\t        T\n",
    "F\tF\t T\t      T\t            T\t        T\t        T\n",
    "Interpretation:\n",
    ". The expression ((ùëÉ‚áíùëÑ)‚àß(ùëÑ‚áíùëÉ))=(ùëÉ=ùëÑ) is true in all cases.\n",
    ". Therefore, the expression is a tautology (since it is true for all combinations of truth values).\n",
    "\n",
    "# Final Answers:\n",
    "1. (P‚à®Q)‚áí(¬¨P): Contingency (not a tautology or contradiction).\n",
    "\n",
    "2. (P‚áíQ)=(¬¨P‚à®Q): Tautology (true for all combinations of truth values).\n",
    "\n",
    "3. ((P‚áíQ)‚àß(Q‚áíP))=(P=Q): Tautology (true for all combinations of truth values).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9) Explain defuzzification and commonly used defuzzification methods.\n",
    "\n",
    "Sol) \n",
    "# Defuzzification:\n",
    "Defuzzification is the process of converting a fuzzy value (a fuzzy set) into a precise, crisp value. It is the final step in the fuzzy logic system after fuzzification (where crisp input values are transformed into fuzzy sets), inference (where rules are applied to the fuzzy sets), and aggregation (where fuzzy results are combined).\n",
    "\n",
    "The goal of defuzzification is to extract a single, definitive output from the fuzzy system for use in decision-making or control systems. It is necessary because the output of the fuzzy inference process is typically a fuzzy set, but the system needs a specific value to take action, such as in a control system or decision-making process.\n",
    "\n",
    "# Commonly Used Defuzzification Methods:\n",
    "1. Centroid Method (Center of Gravity - COG):\n",
    "\n",
    "The Centroid Method, also called the Center of Gravity (COG), is the most widely used and most common defuzzification technique. It calculates the crisp value by finding the center of gravity of the area under the curve of the fuzzy set.\n",
    "\n",
    "2. Mean of Maxima (MOM):\n",
    "\n",
    "The Mean of Maxima (MOM) method is another defuzzification technique that computes the average of the values where the membership function reaches its maximum value. This method is often used when the fuzzy set has multiple peaks or modes.\n",
    "\n",
    "3. Largest of Maximum (LOM):\n",
    "\n",
    "The Largest of Maximum (LOM) method defuzzifies the output by selecting the largest \n",
    "ùë•\n",
    "x-value where the membership function attains its maximum value. This method is generally used when a conservative approach is required (e.g., in control systems where the system must choose the \"safest\" or most extreme option).\n",
    "\n",
    "4. Smallest of Maximum (SOM):\n",
    "\n",
    "The Smallest of Maximum (SOM) method is the opposite of the LOM method. It selects the smallest value from the set of \n",
    "ùë•\n",
    "x-values where the membership function attains its maximum value. This method is used when a more \"aggressive\" or conservative approach is needed, where the smallest possible value is selected to avoid overestimation.\n",
    "\n",
    "5. Weighted Average Method:\n",
    "\n",
    "The Weighted Average method calculates the crisp output by taking the weighted average of the values associated with the fuzzy sets, where the weights are the membership degrees of the fuzzy sets. This method is used when we have multiple fuzzy sets contributing to the output and want to consider both the value and the degree of membership.\n",
    "\n",
    "# Conclusion:\n",
    "Defuzzification is a crucial step in fuzzy logic systems where we need to derive a crisp value from a fuzzy set. The choice of defuzzification method depends on the nature of the problem, the system requirements (precision, safety, etc.), and the characteristics of the fuzzy set. Common methods include centroid, mean of maxima, largest of maximum, smallest of maximum, and weighted average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10) explain the gradient descent algorithm and derive an expression to update weights and biases\n",
    "\n",
    "Sol) \n",
    "# Gradient Descent Algorithm:\n",
    "Gradient Descent is an optimization algorithm used to minimize a function by iteratively moving toward the minimum of the function. In machine learning, it is commonly used to minimize the cost or loss function to find the optimal parameters (weights and biases) in models like neural networks.\n",
    "\n",
    "The key idea behind gradient descent is to update the parameters (weights and biases) in the opposite direction of the gradient of the cost function with respect to the parameters. This helps the model to converge to a minimum point where the cost is as low as possible.\n",
    "\n",
    "# Steps in the Gradient Descent Algorithm:\n",
    "1. Initialize Parameters: Initialize the weights (ùëä) and biases (b) with random values.\n",
    "\n",
    "2. Compute the Cost Function: The cost function (often Mean Squared Error or Cross-Entropy) is computed, which quantifies how well the model is performing.\n",
    "\n",
    "3. Compute Gradients: Calculate the gradients of the cost function with respect to the weights and biases. The gradient indicates the direction in which the cost function increases most steeply.\n",
    "\n",
    "4. Update Parameters: Update the weights and biases by moving in the opposite direction of the gradients.\n",
    "\n",
    "5. Repeat: Repeat the process until the cost converges to a minimum or after a certain number of iterations.\n",
    "\n",
    "The gradient descent algorithm works by iteratively adjusting the parameters using the following update rules:\n",
    "\n",
    "\n",
    "1. Gradient Descent for Weights and Biases:\n",
    "Consider a neural network with one layer. Let the output of the network be y^, and the true output (target) be ùë¶. The cost function (mean squared error) is defined as:\n",
    "\n",
    "ùêΩ(ùëä,ùëè) = 1/2 ‚àë(ùë¶ùëñ'‚àíùë¶ùëñ^)^2\n",
    "\n",
    "2. Deriving the Gradient of the Cost Function:\n",
    "We need to compute the gradients of the cost function with respect to weights and biases.\n",
    "Thus, the gradient with respect to the weights is:\n",
    "\n",
    "‚àÇùêΩ(ùëä,ùëè) / ‚àÇb = ‚àë(ùë¶ùëñ‚àíùë¶i^) ‚ãÖ ùëì‚Ä≤(ùëä ‚ãÖ ùëãùëñ +ùëè)\n",
    "\n",
    "3. Updating Weights and Biases:\n",
    "Using the gradients computed above, the weights and biases are updated using the following rules:\n",
    "Substituting the gradient for bias:\n",
    "\n",
    "ùëè=ùëè‚àíùõº ‚ãÖ ‚àë(ùë¶ùëñ‚àíùë¶ùëñ^) ‚ãÖ ùëì‚Ä≤(ùëä ‚ãÖ ùëãùëñ + ùëè)\n",
    "\n",
    "4. Stochastic Gradient Descent (SGD):\n",
    "In practice, we often use Stochastic Gradient Descent (SGD), where the gradients are computed for a single data point at a time (instead of averaging over the entire dataset). This reduces the computational cost and can speed up convergence, but it introduces noise into the optimization process, which can sometimes help escape local minima.\n",
    "\n",
    "The update rules for SGD are:\n",
    "\n",
    "ùëä = ùëä ‚àí ùõº ‚ãÖ (ùë¶ùëñ‚àíùë¶ùëñ^) ‚ãÖ ùëì‚Ä≤(ùëä‚ãÖùëãùëñ+ùëè)‚Äã\n",
    " \n",
    "ùëè = ùëè‚àíùõº ‚ãÖ (ùë¶ùëñ‚àíùë¶ùëñ^) ‚ãÖ ùëì‚Ä≤(ùëä ‚ãÖ ùëãùëñ + ùëè)\n",
    "\n",
    "# Conclusion:\n",
    "Gradient Descent is a fundamental optimization algorithm used to minimize a cost function by adjusting the parameters (weights and biases) iteratively. The weights and biases are updated by moving in the direction opposite to the gradient of the cost function. This process continues until convergence, where the cost function reaches a minimum (or close to minimum).\n",
    "\n",
    "The update rules for weights and biases are derived by computing the gradients of the cost function with respect to each parameter. In practice, a learning rate (ùõº) is used to control the step size in the update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10) Design a neural network to classify 60,000 handwritten digits, analyze its computational complexity , and justify the choice of architecture.\n",
    "\n",
    "Sol)\n",
    "Design a neural network to classify 60,000 handwritten digits, analyze its computational complexity , and justify the choice of architecture.\n",
    "\n",
    "Neural Network Architecture\n",
    "1. Input Layer\n",
    ". Dimensions: 784 (flattened pixels of the 28 √ó 28 image).\n",
    ". Each pixel's value (0‚Äì255) is normalized to the range [0, 1].\n",
    "2. Hidden Layers\n",
    ". Layer 1 (Fully Connected, Dense):\n",
    "    . Neurons: 128 \n",
    "    . Activation: ReLU (Rectified Linear Unit)\n",
    "    . Reason: Captures non-linear patterns while reducing the risk of vanishing gradients.\n",
    ". Layer 2 (Fully Connected, Dense):\n",
    "    . Neurons: 64 \n",
    "    . Activation: ReLU\n",
    "    . Reason: A smaller layer focuses on higher-level feature abstraction.\n",
    "3. Output Layer\n",
    ". Neurons: 10 (one for each digit class).\n",
    ". Activation: Softmax\n",
    ". Reason: Converts raw scores into probabilities, enabling multi-class classification.\n",
    "4. Loss Function\n",
    ". Categorical Cross-Entropy Loss: Suitable for multi-class classification tasks.\n",
    "5. Optimizer\n",
    ". Adam Optimizer: Combines the benefits of momentum and adaptive learning rates, making it computationally efficient.\n",
    "\n",
    "# Analysis of Computational Complexity\n",
    "1. Forward Propagation\n",
    "For each fully connected layer, the computational complexity is determined by the number of multiplications and additions:\n",
    "\n",
    "Complexity¬†per¬†layer = (Number¬†of¬†Inputs) √ó (Number¬†of¬†Neurons) + (Number¬†of¬†Neurons) \n",
    "For the given architecture:\n",
    "\n",
    "Input to Hidden Layer 1:\n",
    "(784 √ó 128) + 128 = 100, 480\n",
    "\n",
    "Hidden Layer 1 to Hidden Layer 2:\n",
    "(128 √ó 64) + 64 = 8 , 256\n",
    "\n",
    "Hidden Layer 2 to Output Layer:\n",
    "(64 √ó 10) + 10 = 650\n",
    "\n",
    "Total complexity for forward pass:\n",
    "100,480 + 8,256 + 650 = 109, 386\n",
    "\n",
    "2. Backpropagation\n",
    "The backpropagation step requires twice the computations as forward propagation (due to gradient calculations), so:\n",
    "\n",
    "Backpropagation¬†Complexity = 2 √ó 109, 386 = 218 , 772\n",
    "\n",
    "3. Total Complexity Per Sample\n",
    "Total¬†Complexity¬†(Forward¬†+¬†Backward) = 109, 386 + 218, 772 = 328, 158\n",
    "\n",
    "For 60,000 training samples:\n",
    "\n",
    "60,000 √ó 328, 158 = 19.69 √ó 10^9 operations¬†per¬†epoch.\n",
    "\n",
    "# Justification for the Chosen Architecture\n",
    "1. Input Size Handling:\n",
    "\n",
    ". The input layer of 784 neurons matches the flattened \n",
    "28 √ó 28 images.\n",
    ". Efficiently captures pixel-level features.\n",
    "2. Hidden Layer Sizes:\n",
    "\n",
    ". 128 neurons in the first hidden layer: Balances expressive power and computational efficiency.\n",
    ". 64 neurons in the second hidden layer: Refines higher-level features while reducing parameters.\n",
    "3. Activation Functions:\n",
    "\n",
    ". ReLU in hidden layers ensures non-linearity and avoids vanishing gradients.\n",
    ". Softmax in the output layer provides probabilities for multi-class classification.\n",
    "4. Regularization and Optimization:\n",
    "\n",
    ". Use of dropout or L2 regularization (not explicitly mentioned above) can prevent overfitting.\n",
    ". Adam optimizer adapts learning rates and improves convergence.\n",
    "5. Scalability:\n",
    "\n",
    ". The architecture is simple yet scalable for larger datasets or image sizes, making it an ideal starting point for classification tasks.\n",
    "# Conclusion\n",
    "The proposed neural network is computationally efficient for the MNIST dataset while being simple enough to train on modern hardware (e.g., GPUs). It effectively balances accuracy, training speed, and generalization by using appropriate layer sizes, activation functions, and optimization techniques.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11) \n",
    "\n",
    "Sol) \n",
    "# Genetic Algorithm (GA):\n",
    "A Genetic Algorithm (GA) is a search heuristic used to solve optimization and search problems. It is inspired by the process of natural selection and the principles of genetics, where solutions evolve over generations to find the optimal or near-optimal solution to a problem.\n",
    "\n",
    "In GAs, a population of candidate solutions (called individuals or chromosomes) is evolved over successive generations using operators inspired by natural genetics, such as selection, crossover (recombination), and mutation. The individuals are evaluated based on a fitness function, which measures how good a solution is. The algorithm selects the best solutions and combines them to form new individuals, gradually improving the population's overall quality.\n",
    "\n",
    "Key Components of Genetic Algorithm:\n",
    "1. Population: A set of possible solutions to the problem.\n",
    "2. Chromosomes: The representation of individual solutions in the population (e.g., as binary strings or real-valued vectors).\n",
    "3. Selection: The process of choosing the best individuals based on their fitness.\n",
    "4. Crossover (Recombination): The process of combining two parent solutions to produce offspring.\n",
    "5. Mutation: A small random change in an individual‚Äôs chromosome to maintain genetic diversity.\n",
    "6. Fitness Function: A function used to evaluate how good a solution is.\n",
    "\n",
    "# Biological Generics\n",
    "1. Natural evolution of species in the real world.\n",
    "2. A population of organisms (e.g., animals, plants).\n",
    "3. DNA, a molecule that encodes genetic information.\n",
    "4. Survival of the fittest: individuals are selected based on fitness to survive and reproduce.\n",
    "5. Genetic recombination during reproduction between two parent organisms.\n",
    "6. Random genetic mutations that occur naturally during DNA replication.\n",
    "7. \tSurvival and reproduction ability in the natural environment (e.g., ability to find food, avoid predators).\n",
    "8. To increase the fitness of individuals in the population for survival.\n",
    "9. Evolution occurs over many generations, leading to better-adapted species.\n",
    "10. Offspring inherit genetic material from their parents, with variations introduced via mutations.\n",
    "\n",
    "# Genetic Algorithms\n",
    "1. Computational optimization algorithm inspired by biology.\n",
    "2. A population of candidate solutions (e.g., strings, vectors).\n",
    "3. A data structure (typically binary strings or real-valued vectors) representing a solution.\n",
    "4. Selection of individuals based on fitness function, often using methods like roulette-wheel or tournament selection.\n",
    "5. Crossover combines two parent solutions to create offspring with shared traits.\n",
    "6. Random changes to an individual‚Äôs chromosome to introduce diversity.\n",
    "7. Fitness function evaluates how good a solution is in solving the problem (e.g., minimizing an error function).\n",
    "8. To find the best or near-optimal solution to a given problem.\n",
    "9. Population evolves over generations to find an optimal solution.\n",
    "10. Offspring are generated by combining the genetic material of selected parents and introducing mutations.\n",
    "\n",
    "Summary:\n",
    "Genetic algorithms are inspired by biological genetics but applied to solve optimization problems. The core concepts, such as population, selection, crossover, mutation, and fitness, mimic the process of natural evolution, where the best solutions evolve over time. However, instead of biological survival, GAs seek the most effective solution to a computational problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11) Explain with an example where the genetic algorithm is useful. Write python code to implement a Genetic algorithm to solve the knapsack problem.\n",
    "\n",
    "Sol) \n",
    "# Use Case of Genetic Algorithm\n",
    "Genetic Algorithms (GAs) are particularly useful for solving optimization problems where the search space is large, complex, or non-linear, and conventional methods struggle to find a solution efficiently.\n",
    "\n",
    "Example: The Knapsack Problem\n",
    "In the Knapsack Problem, we aim to maximize the value of items placed in a knapsack without exceeding its weight limit. This problem is NP-hard and serves as an excellent candidate for GAs due to the combinatorial nature of the search space.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "items = [\n",
    "    {\"weight\": 2, \"value\": 3},\n",
    "    {\"weight\": 3, \"value\": 4},\n",
    "    {\"weight\": 4, \"value\": 8},\n",
    "    {\"weight\": 5, \"value\": 8},\n",
    "    {\"weight\": 9, \"value\": 10},\n",
    "]\n",
    "max_weight = 15\n",
    "population_size = 10\n",
    "generations = 100\n",
    "mutation_rate = 0.1\n",
    "\n",
    "def fitness(individual):\n",
    "    total_weight = sum(individual[i] * items[i][\"weight\"] for i in range(len(items)))\n",
    "    total_value = sum(individual[i] * items[i][\"value\"] for i in range(len(items)))\n",
    "    if total_weight > max_weight:\n",
    "        return 0\n",
    "    return total_value\n",
    "\n",
    "def generate_population(size):\n",
    "    return [[random.randint(0, 1) for _ in range(len(items))] for _ in range(size)]\n",
    "\n",
    "def select(population):\n",
    "    fitness_scores = [fitness(ind) for ind in population]\n",
    "    total_fitness = sum(fitness_scores)\n",
    "    if total_fitness == 0:\n",
    "        return random.choice(population)\n",
    "    probabilities = [f / total_fitness for f in fitness_scores]\n",
    "    return population[random.choices(range(len(population)), probabilities)[0]]\n",
    "\n",
    "def crossover(parent1, parent2):\n",
    "    point = random.randint(1, len(parent1) - 1)\n",
    "    child1 = parent1[:point] + parent2[point:]\n",
    "    child2 = parent2[:point] + parent1[point:]\n",
    "    return child1, child2\n",
    "\n",
    "def mutate(individual, rate):\n",
    "    for i in range(len(individual)):\n",
    "        if random.random() < rate:\n",
    "            individual[i] = 1 - individual[i]\n",
    "\n",
    "def genetic_algorithm():\n",
    "    population = generate_population(population_size)\n",
    "    for generation in range(generations):\n",
    "        new_population = []\n",
    "        for _ in range(population_size // 2):\n",
    "            parent1 = select(population)\n",
    "            parent2 = select(population)\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            mutate(child1, mutation_rate)\n",
    "            mutate(child2, mutation_rate)\n",
    "            new_population.extend([child1, child2])\n",
    "        population = new_population\n",
    "\n",
    "    best_individual = max(population, key=fitness)\n",
    "    best_value = fitness(best_individual)\n",
    "    total_weight = sum(best_individual[i] * items[i][\"weight\"] for i in range(len(items)))\n",
    "    return best_individual, best_value, total_weight\n",
    "\n",
    "best_solution, best_value, best_weight = genetic_algorithm()\n",
    "print(\"Best Solution:\", best_solution)\n",
    "print(\"Total Value:\", best_value)\n",
    "print(\"Total Weight:\", best_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
